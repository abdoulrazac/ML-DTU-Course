{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stanislav Borysov [stabo@dtu.dk], DTU Management*\n",
    "# Advanced Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Data Mining - Part 1: Social media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of valuable data can be collected from online sources. It can be used to get insights, make predictions, etc. In this notebook, we're going to practice data collection from online sources using API. Particularly, we will collect social media data from Twitter and weather data from Weatherbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting Twitter data\n",
    "*Based on https://www.toptal.com/python/twitter-data-mining-using-python*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**! WARNING !**\n",
    "\n",
    "**In order to make a developer account, you will need to use your email and phone number. The account can be deleted after class. However, if you do not want to use your personal data, you can go through Section 1 in the solutions notebook (Part 1 - Twitter-solutions.ipynb). After that, you can proceed with Section 2 \"Twitter data analysis\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Creating developer account\n",
    "\n",
    "In order to use Twitter’s API, we have to create a developer account on the Twitter website.\n",
    "\n",
    "1. Sign in or create a Twitter account and apply for a developer account at https://developer.twitter.com/.\n",
    "    1. Choose Academic / Student\n",
    "    2. You need to add and verify your phone number  \n",
    "    3. Fill in the following answers:\n",
    "        1. \"How will you use the Twitter API or Twitter data?\": \"In English, please describe how you plan to use Twitter data and/or APIs. For students and teachers, please include the name of the school, the name of the instructor and the course number (if available). The more detailed the response, the easier it is to review and approve.\"\n",
    "        \n",
    "        > I am a student at the Technical University of Denmark. I would like to learn more about web data mining and data science. Currently, I am attending a Data Science course. I will use the data for educational purposes only in the class. The analysis involves very basic natural language processing. The collected data will not be published anywhere or displayed to anyone. No commercial use or product development is expected.\n",
    "        \n",
    "        2. **\"The specifics\": switch to \"No\" everywhere.**\n",
    "    4. Accept terms and conditions\n",
    "    5. Confirm your email if asked\n",
    "2. Create a new app\n",
    "     1. App name (required): Any name that not already taken (e.g., *testappxxx12345*)\n",
    "     2. Application description (required): *This is a test app.*\n",
    "     3. Website URL (required): (any fake website) *https://example.com*\n",
    "     4. Tell us how this app will be used (required): *This app will be used for education purposes only. No commercial use is expected. More characters to hit the 100-characters limit.*\n",
    "3. Once your project has been created, click on the “Keys and Access Tokens” tab. You should now be able to see your consumer secret and consumer key.\n",
    "     1. Copy your API key and API secret key to the cell below.\n",
    "     2. Generate Access token and Access token secret and copy them to the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Install tweepy\n",
    "Tweepy is a python library to make access to the Twitter data easier. You can install tweepy using several options:\n",
    "- Anaconda-Navigator: add chanel ```conda-forge```, press \"update index...\", search for ```tweepy```, install\n",
    "- pip: pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For other languages, check https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Authenticating\n",
    "Now that we have the necessary tools ready, we can start coding! The baseline of each application we’ll build today requires using Tweepy to create an API object which we can call functions with. In order to create the API object, however, we must first authenticate ourselves with our developer information.\n",
    "\n",
    "First, let’s import Tweepy and add our own authentication information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# replace these values with yours\n",
    "api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "api_secret_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to create our API object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Example 1: Your Timeline\n",
    "In the first example, we’ll be pulling the ten most recent tweets from your Twitter feed. We’ll do this by using the API object’s ```home_timeline()``` function. We can then store the result in a variable, and loop through it to print the results.\n",
    "\n",
    "Hints:\n",
    "- use ```public_tweets = api.home_timeline()```\n",
    "- and then iterate through the pulled tweets\n",
    "```\n",
    "for tweet in public_tweets:\n",
    "    ...\n",
    "    do something with the tweet (for example, print its text)\n",
    "```\n",
    "- you can access the text of the tweet using ```tweet.text```\n",
    "\n",
    "WARNING! You won't get any results if you don't follow anyone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should look like a bunch of random tweets, followed by the URL to the tweet itself. Following the link to the tweet will often bring you to the tweet itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Example 2: Tweets from a Specific User\n",
    "\n",
    "In this example, we’ll simply pull the latest twenty tweets from a user of our choice.\n",
    "\n",
    "First, we’ll examine the Tweepy documentation at http://docs.tweepy.org/en/v3.5.0/api.html to see if a function like that exists. With a bit of research, we find that the ```user_timeline()``` function is what we’re looking for http://docs.tweepy.org/en/v3.5.0/api.html#API.user_timeline.\n",
    "\n",
    "We can see that the ```user_timeline()``` function has some useful parameters we can use, specifically id (the ID of the user) and count (the number of tweets we want to pull). Note that we can only pull a limited number of tweets per query due to the Twitter’s rate limits (15 calls every 15 minutes). See https://developer.twitter.com/en/docs/basics/rate-limiting and https://developer.twitter.com/en/docs/basics/rate-limits for further details.\n",
    "\n",
    "Let’s try to pull the latest twenty tweets from the twitter account ```NyTimes```.\n",
    "\n",
    "Hints: \n",
    "- use ```tweets = api.user_timeline(id=userName, count=tweetCount)``` and print text of the tweets using the ``for`` loop like in the previous example\n",
    "- the user name is \"nytimes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tweets are cut, probably, due to the old limit of 140 symbols (which is currently 280). To get full text of the tweets, you need to use the following command ```tweets = api.user_timeline(id=userName, count=tweetCount, tweet_mode='extended')```. \n",
    "\n",
    "WARNING! ```tweet.text``` is not available anymore and one needs to use ```tweet.full_text``` instead. It seems that this is not documented in the Tweepy documentation, so we'd have to figure it out ourselves by searching on the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular applications of this type of data can include:\n",
    "\n",
    "- Running analysis on specific users, and how they interact with the world\n",
    "- Finding Twitter influencers and analyzing their follower trends and interactions\n",
    "- Monitoring the changes in the followers of a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Example 3: Finding Tweets Using a Keyword\n",
    "\n",
    "Let’s do one last example: Getting the most recent tweets that contain a keyword. This can be extremely useful if you want to monitor specifically mentioned topics in the Twitter world, or even to see how your business is getting mentioned. Let’s say we want to see how Twitter’s been mentioning Tesla.\n",
    "\n",
    "After looking through the Tweepy documentation, the ```search()``` function seems to be the best tool to accomplish our goal http://docs.tweepy.org/en/v3.5.0/api.html#API.search.\n",
    "\n",
    "The most important parameter here is ```q``` - the query parameter, which is the keyword we’re searching for. We can also set the language parameter so we don’t get any tweets from an unwanted language. Let’s only return English (“en”) tweets.\n",
    "\n",
    "We can now modify our code to reflect the changes we want to make. We first create variables to store our parameters (query and language), and then call the function via the API object. Let’s also print the screen name of the user that created the tweet in our loop.\n",
    "\n",
    "Hints: \n",
    "- use ```tweets = api.search(q=query, lang=language, tweet_mode='extended')``` to get the tweets\n",
    "- the query word is \"tesla\" and laguage is \"en\"\n",
    "- to access the name of a user, use ```tweet.user.screen_name```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some practical ways you can use this information:\n",
    "\n",
    "- Create a spatial graph on where your company is mentioned the most around the world\n",
    "- Run sentiment analysis on tweets to see if the overall opinion of your company is positive or negative\n",
    "- Create social graphs of the most popular users that tweet about your company or product\n",
    "- Estimate popularity of an event (e.g. sports game, music concert) to analyze its impact on a public transport system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. The JSON behind the results\n",
    "\n",
    "In the examples above, we printed the text from each tweet using ```tweet.text``` or ```tweet.full_text```. To refer to specific attributes of each tweet object, we have to look at the JSON returned by the Twitter API.\n",
    "\n",
    "The result you receive from the Twitter API is in a JSON format and has quite an amount of information attached. For simplicity, this lecture mainly focuses on the ```full_text``` attribute of each tweet and information about the tweeter (the user that created the tweet). For the above sample, you can see the entire returned JSON object here: https://developer.twitter.com/en/docs/api-reference-index.\n",
    "\n",
    "Here’s a quick look at some attributes a tweet has to offer. To access the JSON behind each tweet, we can use ```tweet._json```. To print this dictionary, another function called ```pprint``` can be helpful:\n",
    ">```\n",
    "from pprint import pprint\n",
    "pprint(tweet._json)\n",
    "```\n",
    "\n",
    "Print JSON of the first tweet using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tweet contains a lot of data! Read the Twitter docs if you want to understand it better.\n",
    "\n",
    "The JSON is represented by a dictionary in Python. For example, if you wanted to find the date the tweet was created, you would query it with ```tweet._json['created_at']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8. Saving data into a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the retrieved tweets to a JSON file for further analysis. \n",
    "\n",
    "**Rule of thumb: It's better to save more (redundant at the first glance) data rather than collect the missing data later.**\n",
    "\n",
    "To work with the JSON data, we will use the ```json``` package. First, ```import json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to save the data. We want the following format: each line in the file should be a JSON string. \n",
    "\n",
    "Hints:\n",
    "- to write one line to a file, one can use \n",
    "```\n",
    "outfile = open(file_name, 'w')\n",
    "outfile.write(string_to_write + '\\n') \n",
    "# remember to include the end of line character\n",
    "outfile.close()\n",
    "```\n",
    "- use a loop after ```open``` (and before ```close```) to write multiple lines\n",
    "- to convert a json dictionary into a string, use ```json.dumps(tweet._json)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the number of lines in the file to make sure that it contains the correct number of tweets.\n",
    "\n",
    "Hint: Open the file, read the lines and find their number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect the data to be used in this class, the following script was used. The script is given for the reference. Please do not run it as you might exceed the Twitter limits."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The search term you want to find\n",
    "query = \"tesla\"\n",
    "# Language code (follows ISO 639-1 standards)\n",
    "language = \"en\"\n",
    "max_tweets = 1000\n",
    "\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "while len(searched_tweets) < max_tweets:\n",
    "    count = max_tweets - len(searched_tweets)\n",
    "    try:\n",
    "        new_tweets = api.search(q=query, count=count, lang=language, \n",
    "                                max_id=str(last_id - 1), tweet_mode='extended')\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "    except tweepy.TweepError as e:\n",
    "        # depending on TweepError.code, one may want to retry or wait\n",
    "        # to keep things simple, we will give up on an error\n",
    "        print(\"Error\")\n",
    "        break   \n",
    "        \n",
    "with open('tesla_tweets_1000.txt', 'w') as outfile:\n",
    "    for tweet in searched_tweets:\n",
    "        outfile.write(json.dumps(tweet._json) + '\\n')\n",
    "\n",
    "print(len(searched_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Twitter data analysis\n",
    "*Based on https://www.coursera.org/specializations/jhu-data-science*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the JSON data from 'tesla_tweets_1000.txt' into a list of JSON dictionaries and print the number of tweets and the first tweet. \n",
    "\n",
    "Hints: \n",
    "- the file has the following structure, where each line contains a string representation of a JSON dictionary, which you need to parse:\n",
    "\n",
    "> {...}\\n\n",
    "\n",
    "> {...}\\n\n",
    "\n",
    "> {...}\\n\n",
    "\n",
    "> ...\n",
    "\n",
    "- use ```json.loads(string)``` to parse the string into a json dictionary\n",
    "- use ```pprint``` instead of ```print``` to get 'pretty' formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print creation time, username and text for the first 10 tweets. To print each tweet, it's convenient to define a new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tweet(tweet):\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Derive the sentiment of each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll compute the sentiment of each tweet based on the sentiment scores of the terms in the tweet. For the simplicity, we assume that the sentiment of a tweet is equivalent to the sum of the sentiment scores for each term in the tweet.\n",
    "\n",
    "The file AFINN-111.txt contains a list of pre-computed sentiment scores. Each line in the file contains a word or phrase followed by a sentiment score. For example,\n",
    ">catastrophic\t-4\n",
    "\n",
    ">breathtaking\t5\n",
    "\n",
    "Each word or phrase that is found in a tweet but not found in AFINN-111.txt should be given a sentiment score of 0. See the file AFINN-README.txt for more information.\n",
    "\n",
    "To use the data in the AFINN-111.txt file, you may find it useful to build a dictionary. The dictionary should have the following format: ```sent_dictionary={'term': score}```. Note that the AFINN-111.txt file format is tab-delimited, meaning that the term and the score are separated by a tab character. A tab character can be identified a \"\\t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sent_dictionary(sent_filename):\n",
    "    # initialize an empty dictionary\n",
    "    sent_dictionary = {} \n",
    "    # ...\n",
    "    #print sent_dictionary.items() \n",
    "    return sent_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function to rate sentiments of the tweets. To parse the text of each tweet and get a list of words, the following code might be useful:\n",
    "\n",
    "```\n",
    "import string\n",
    "words = [word.strip(string.punctuation) for word in text.split()]\n",
    "```\n",
    "\n",
    "Here, ```word.strip(string.punctuation)``` is used to remove punctuation from each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def rate_sentiments(tweets, sent_dictionary):\n",
    "    scores = [] # you might use another data structure if you want...\n",
    "    # ...\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the functions to build the dictionary and get a list of scores for each tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the scores. First, we can plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What insights can be got from it? Let's also calculate and print a mean score of all tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's slightly positive! The time series of mean scores can be used, for example, to predict the stock price of a company. Can you come up with the other possible applications of the sentiment scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the top 10 positive and 10 negative tweets.\n",
    "\n",
    "Hint: To get indices of the tweets when sorting the list of scores, you might want to add these indices into the list via ```scores_ind = enumerate(scores)``` and sort the list on the second value of each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do they make any sense?\n",
    "\n",
    "Automatic sentiment detection is one of the hardest problems in natural language processing (NLP). It's not as simple as a sum of sentiments of separate words since one word can completely change the meaning of a sentence. Also, you can think of such things as subjectivity, tone, context, irony, sarcasm, and many others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Compute Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing word frequency is one of the basic routine tasks in NLP. The frequency can be used to do document classification, retrieval, topic modeling. Let's compute frequency of each word in all tweets as ``freq=number_of_word_occurrences/total_number_of_words``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(tweets):\n",
    "    word_freq = {}\n",
    "    # ...\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the frequencies of the top 30 most frequent words. \n",
    "\n",
    "Hints: \n",
    "- dictionaries in python have no order, so it doesn't make sense to sort them. Convert the frequency dictionary into a list of tuples first: ```[(word, frequency)]```\n",
    "- to show labels on the x-axis of the plot vertically, you can use ```plt.xticks(rotation=90)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, such non-informative words as \"the\", \"of\" or \"a\" are among the most frequent ones. Removing these words, called \"stop words\", is one of the first steps in text preprocessing in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Top hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's us compute the most popular hashtags in a similar manner as word frequency. Print the top 10 hashtags and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_hashtags(tweets):\n",
    "    hashtags = {}\n",
    "    # ...\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. User location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to figure out where our tweets come from. There are several options to do it:\n",
    "\n",
    "1. The most precise information is contained in ```tweet['coordinates']```. However, as you'll see, it's rare when users report geolocation directly in their tweets.\n",
    "2. Another option is to use ```tweet['place']```.\n",
    "3. Finally, you can try to use the location of the user: ```tweet['user']['location']```. However, this information can be potentially misleading.\n",
    "\n",
    "To check the availability of these data fields, we need to calculate the number of tweets where these attributes are non-empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it doesn't look promising :( \n",
    "\n",
    "Detecting location of the tweets is not so straightforward as ```tweet['coordinates']``` and ```tweet['place']``` are missing for the almost all tweets. Thus, we need to rely on the user location.\n",
    "\n",
    "Data science requires creativity. Can you think of the other approaches to get the place of a tweet? Discuss it with the other students or teacher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the most tweets come from the U.S.A. (you can check if you want), we can try to identify the state where a tweet comes from. We can get this information from the two attributes: \n",
    "1. ```tweet['place']```\n",
    "2. If the first is not available, then ```tweet['user']['location']```\n",
    "\n",
    "But let's first inspect the possible values of the two fields to find the best strategy to extract the state. Print these attributes for all tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that these two fields contain information in a natural language form. Both ```tweet['place']['full_name']``` and ```tweet['user']['location']``` can contain city, full name of a state or its code. To extract the state from a string, we'll use regular expressions.\n",
    "\n",
    "Regular expression is a powerful tool used in almost all programming languages to extract information from string data. Although it has its own sophisticated markup language, we're not going to use it here. You can search for a substring ```query``` in a string using the following code:\n",
    "```\n",
    "import re\n",
    "searchObj = re.search(query, string)\n",
    "if searchObj: \n",
    "    # there is a match\n",
    "else:\n",
    "    # nothing was found\n",
    "```\n",
    "For example, the following code will find matches of the string 'NY' in the string 'Brookville, NY' ignoring the case of the letters:\n",
    "```\n",
    "searchObj = re.search('NY', 'Brookville, NY', re.IGNORECASE)\n",
    "if searchObj:\n",
    "    #this code will be executed as there is a match\n",
    "``` \n",
    "\n",
    "Hints:\n",
    "- don't forget to check ```tweet['place']['country_code']``` as well\n",
    "- search for the full name of a state first and then, if nothing was found, search for a state abbreviation\n",
    "- the dictionary below will help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dict = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_state_from_str(text, states_dict):\n",
    "    state = None\n",
    "    # ...\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's iterate through the tweets again to find a mean value of sentiment scores for each state.\n",
    "\n",
    "Hint: don't compute scores again as you already have done it in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's print the sorted list of the mean sentiment scores for each state. In this case, it can help to get some knowledge about the states where people are positive or negative about Tesla. This can provide valuable insights for the marketing department!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
