{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stanislav Borysov [stabo@dtu.dk], DTU Management*\n",
    "# Advanced Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty in Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: This notebook contains more advanced Python code than the previous ones. You are not supposed to fully understand all the code but rather follow the main steps and understand general principles. There are might be a few other tools and packages available to solve these problems with much less programming.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information collected by the U.S Census Service in 1970s concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston) and has been used extensively throughout the literature to benchmark algorithms. The dataset is small in size with only 506 cases. The data was originally published by *Harrison, D. and Rubinfeld, D.L. Hedonic prices and the demand for clean air, J. Environ. Economics & Management, vol.5, 81-102, 1978.*\n",
    "\n",
    "The following describes the dataset columns:\n",
    "\n",
    "- CRIM - per capita crime rate by town\n",
    "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS - proportion of non-retail business acres per town.\n",
    "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- NOX - nitric oxides concentration (parts per 10 million)\n",
    "- RM - average number of rooms per dwelling\n",
    "- AGE - proportion of owner-occupied units built prior to 1940\n",
    "- DIS - weighted distances to five Boston employment centers\n",
    "- RAD - index of accessibility to radial highways\n",
    "- TAX - full-value property-tax rate per \\$10,000\n",
    "- PTRATIO - pupil-teacher ratio by town\n",
    "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of people of African American descent by town\n",
    "- LSTAT - % lower status of the population\n",
    "- MEDV - Median value of owner-occupied homes in $1000's\n",
    "\n",
    "The MEDV variable is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment about the B variable: An analyst should be extremely careful about the well-known \"correlation vs causation\" problem as well as more recent research related to fairness and biases in machine learning and datasets. You can read about it in many places, for example,*\n",
    "\n",
    "- https://www.technologyreview.com/s/612775/algorithms-criminal-justice-ai/\n",
    "- https://www.iperceptions.com/blog/causation-vs-correlation\n",
    "- https://towardsdatascience.com/is-your-machine-learning-model-biased-94f9ee176b67\n",
    "- https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let us start our analysis by taking look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', \n",
    "    'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'\n",
    "]\n",
    "data = pd.read_csv('data/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our analysis, we will use only a subset of variables as features to predict the house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE']\n",
    "y_column = 'MEDV'\n",
    "X = data.loc[:, X_columns].values\n",
    "y = data[y_column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As common in statistical and machine learning analysis, we will scale the features to the same range. Particularly, we will use `sklearn.preprocessing.MinMaxScaler` to have all the feature values in the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot our target variable against the features, we will use the `seaborn` package. It is a very powerful plotting library which has advanced functionality built on top of  `matplotlib`. For instance, on top of the regular scatter plot, it can plot linear regression fitted for each feature separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "axs = axs.flatten()\n",
    "for i, col in enumerate(X_columns):\n",
    "    sns.regplot(y=y, x=X[:, i], ax=axs[i]) # it also does regression!\n",
    "    axs[i].set_xlabel(col)\n",
    "    axs[i].set_ylabel(y_column)\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shaded area around each regression line. This is a confidence interval for the model mean (i.e., regression coefficients, $\\beta$) calculated using statistical bootstrapping. The concept of a confidence interval is different from the concept of a prediction interval (uncertainty), which is related to the variance of the data distribution itself (e.g., $\\sigma$ in Gaussian):\n",
    "\n",
    "> **Confidence intervals** tell you about how well you have determined the mean. Assume that the data really are randomly sampled from a Gaussian distribution. If you do this many times and calculate a confidence interval of the mean from each sample, you'd expect about 95 % of those intervals to include the true value of the population mean. The key point is that the confidence interval tells you about the likely location of the true population parameter.\n",
    "\n",
    "> **Prediction intervals** tell you where you can expect to see the next data point sampled. Assume that the data really are randomly sampled from a Gaussian distribution. Collect a sample of data and calculate a prediction interval. Then sample one more value from the population. If you do this many times, you'd expect that next value to lie within that prediction interval in 95% of the samples.The key point is that the prediction interval tells you about the distribution of values, not the uncertainty in determining the population mean. Prediction intervals must account for both the uncertainty in knowing the value of the population mean, plus data scatter. So a prediction interval is always wider than a confidence interval.\n",
    "\n",
    "You can read more about the difference between the two concepts [here](https://www.graphpad.com/support/faq/the-distinction-between-confidence-intervals-prediction-intervals-and-tolerance-intervals/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preliminary regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare our models, we will use regular 10-fold cross-validation (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Simple baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple baseline, we will use the mean prediction, which is implemented in `sklearn.dummy.DummyRegressor`. To calculate CV Mean Squared Errors (MSE) of this baseline, we can use `sklearn.model_selection.cross_val_predict` to get CV predictions and then use `sklearn.metrics.mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyRegressor()\n",
    "y_pred = cross_val_predict(model, X, y, cv=kf)\n",
    "error = mean_squared_error(y, y_pred)\n",
    "print(\"MSE: {:0.2f}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be our baseline score for the mean price prediction. We can also visualize these predictions versus the true data on a \"45-degree\" plot.\n",
    "\n",
    "*Sidenote: Plotting routine is usually not particularly challenging but it can be very time-consuming, especially, if you want to make a \"perfect\" plot. In this notebook, we will use predefined functions for plotting. You are encouraged to take a look at them and re-use whenever is needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_45(y_true, y_pred):\n",
    "    # find the limits of the data and add some margins\n",
    "    y_min, y_max = min(min(y_pred), min(y_true)), max(max(y_pred), max(y_true))\n",
    "    eps = 5\n",
    "    y_lim_min = y_min - eps\n",
    "    y_lim_max = y_max + eps\n",
    "    # pyplot plotting\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.plot([y_lim_min, y_lim_max], [y_lim_min, y_lim_max], ls=\"--\", c=\"grey\")\n",
    "    plt.scatter(y_pred, y_true, s=20, alpha=0.3)\n",
    "    plt.xlabel(\"{} Predicted\".format(y_column))\n",
    "    plt.ylabel(\"{} True\".format(y_column))\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "    plt.ylim(y_lim_min, y_lim_max)\n",
    "    plt.xlim(y_lim_min, y_lim_max)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_45(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is not a particularly impressive model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. OLS linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another baseline, we will use Ordinary Least Squares (OLS) linear regression implemented in `sklearn.linear_model.LinearRegression`. This is a very common model used for mean prediction which assumes a constant gaussian error ($\\sigma=\\mathrm{const}$). Repeat all the steps as for the dummy model: calculate CV predictions, their MSE and visualize them using the `plot_45()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV MSE of 34.77 and the 45-degree plot look much better now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Uncertanty prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topic of this lecture is the prediction uncertainty for regression models. It involves modeling of the whole data distribution and not just the mean as in the OLS case. For example, if we assume the data distribution in the Gaussian form, then we need to model two parameters: $\\mu$ and $\\sigma$. Using the log-likelihood (LL) method, we will try to learn both models for $\\mu(X)$ and $\\sigma(X)$ simultaneously. In a nutshell, the method can be described as follows:\n",
    "\n",
    "1. Choose a distribution you would like to fit, e.g. Gaussian, with parameters $\\lambda_1$, $\\lambda_2$, $\\dots$.\n",
    "2. Specify models for the parameters in some parametric (or non-parametric) form, i.e., $\\hat\\lambda_1(X)$, $\\hat\\lambda_2(X)$, $\\dots$.\n",
    "3. Define the LL for the assumed distribution, which depends on the observed data and the models.\n",
    "4. Find the models' parameters which maximize the LL (or, equivalently, minimize the negative LL) using some optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Optimizing log-likelihood using linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we will use a model that is built to be compatible with the `sklearn` model specification. In this case, it can be used in other `sklearn` functions, such as `cross_val_score` and `cross_val_predict`. Although it might look a bit scary, try to read the code below and understand the overall logic. Of course, you are not supposed to implement your sklearn models, however, if you are interested, you can read about Python classes [here](https://www.w3schools.com/python/python_classes.asp) and sklearn estimators [here](http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/). An alternative implementation in plain Python can be found in the Appendix, at the very end of this notebook also just for your reference.\n",
    "\n",
    "*Important note: In the model below, we tried only power transformations of the features. However, other transformations such as `exp` or `log` should work much better.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# new sklearn estimators should inherit from the base class 'sklearn.base.BaseEstimator'\n",
    "class ModelPoly(BaseEstimator):\n",
    "    \n",
    "    # class constructor\n",
    "    def __init__(self, mu_degree=None, sigma_degree=None):\n",
    "        # polynomial degree of the model for mu\n",
    "        self.mu_degree = mu_degree\n",
    "        # polynomial degree of the model for sigma\n",
    "        self.sigma_degree = sigma_degree\n",
    "    \n",
    "    # negative log-likelihood to optimize\n",
    "    # since we use scipy.optimize, it should have only one input variable --\n",
    "    # a numpy array with all the parameters of our models\n",
    "    def loss_(self, params):\n",
    "        # manually update the parameters passed to the function by the optimizer\n",
    "        self.model_mu.named_steps.lr.coef_ = params[:self.model_mu_params_n]\n",
    "        self.model_sigma.named_steps.lr.coef_ = params[self.model_mu_params_n:]\n",
    "        # calculate new predictions\n",
    "        mu = self.model_mu.predict(self.X)\n",
    "        sigma = self.model_sigma.predict(self.X)\n",
    "        # calculate negative log-likelihood\n",
    "        nll = np.log(sigma**2) + (self.y - mu)**2 / sigma**2\n",
    "        nll = np.sum(nll) / 2.0 # sum over samples\n",
    "        return nll\n",
    "    \n",
    "    # fitting the model to the data\n",
    "    def fit(self, X, y):\n",
    "        # just to check that we have everything needed\n",
    "        if self.mu_degree is None or self.sigma_degree is None:\n",
    "            raise Exception(\"mu_degree is None or sigma_degree is None\")\n",
    "        # reference to the data\n",
    "        self.X, self.y = X, y\n",
    "        # specify linear models with power transformations\n",
    "        self.model_mu = Pipeline([\n",
    "            (\"pf\", PolynomialFeatures(degree=self.mu_degree, include_bias=True)),\n",
    "            (\"lr\", LinearRegression(fit_intercept=False))\n",
    "        ])\n",
    "        self.model_sigma = Pipeline([\n",
    "            (\"pf\", PolynomialFeatures(degree=self.sigma_degree, include_bias=True)),\n",
    "            (\"lr\", LinearRegression(fit_intercept=False))\n",
    "        ])\n",
    "        # the two lines below virtually do nothing\n",
    "        self.model_mu.named_steps.pf.fit(X)\n",
    "        self.model_sigma.named_steps.pf.fit(X)\n",
    "        # although we do not fit and use intercept as it is included in zero-power ('include_bias=True')\n",
    "        # of the polynomial, sklearn does want to assign some value to the intercept anyway,\n",
    "        # it gives an error otherwise\n",
    "        self.model_mu.named_steps.lr.intercept_ = 0\n",
    "        self.model_sigma.named_steps.lr.intercept_ = 0\n",
    "        # number of parameters for each model\n",
    "        self.model_mu_params_n = self.model_mu.named_steps.pf.n_output_features_\n",
    "        self.model_sigma_params_n = self.model_sigma.named_steps.pf.n_output_features_\n",
    "        # try to understand the following line yourself\n",
    "        params = np.full((self.model_mu_params_n + self.model_sigma_params_n,), 0.1)\n",
    "        # run optimization using Powell's method, which does not require gradients or Hessian matrix\n",
    "        res = minimize(self.loss_, params, method='Powell', options={\n",
    "            'xtol': 1e-8, \n",
    "            'disp': True\n",
    "        })\n",
    "        # save the results (the optimal parameters)\n",
    "        self.model_mu.named_steps.lr.coef_ = res.x[:self.model_mu_params_n]\n",
    "        self.model_sigma.named_steps.lr.coef_ = res.x[self.model_mu_params_n:]\n",
    "        # we do not need the references to the data anymore\n",
    "        self.X, self.y = None, None\n",
    "    \n",
    "    # prediction of mu\n",
    "    def predict_mu(self, X):\n",
    "        return self.model_mu.predict(X)\n",
    "    \n",
    "    # prediction of sigma\n",
    "    def predict_sigma(self, X):\n",
    "        return self.model_sigma.predict(X)\n",
    "    \n",
    "    # by default, our model predicts just mu\n",
    "    def predict(self, X):\n",
    "        return self.predict_mu(X)\n",
    "    \n",
    "    # calculate LL for the data\n",
    "    def score(self, X, y):\n",
    "        # reference to the data\n",
    "        self.X, self.y = X, y\n",
    "        params = np.concatenate((self.model_mu.named_steps.lr.coef_, \n",
    "                                 self.model_sigma.named_steps.lr.coef_), axis=None)\n",
    "        loss = self.loss_(params)\n",
    "        # we do not need the references to the data anymore\n",
    "        self.X, self.y = None, None\n",
    "        return -loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having implemented a sklearn-compatible estimator, we can use it as any other sklearn model. First, we will try the linear mean $\\mu(X)=\\beta_0+\\beta_1x_1+\\alpha_2x_2+\\dots$ and constant variance $\\sigma(X)=\\alpha_0$, which should produce the equivalent solution to the OLS LR above. The linear mean model with constant variance can be defined as \n",
    "\n",
    ">```model = ModelPoly(1, 0)```\n",
    "\n",
    "Repeat all the steps as for the dummy and LR models: calculate CV predictions, their MSE and visualize them using the `plot_45()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelPoly(1, 0)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV MSE should be almost the same as for the LR. They might be slightly different because of using the optimization procedure instead of the analytical OLS solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important idea is that the model's LL can serve as metrics to compare different probabilistic models and not just their mean predictions. We can calculate it using `sklearn.model_selection.cross_val_score`. If a scoring function is not specified in `cross_val_score`, then the `model.score(X, y)` function will be used for this. In the `PolyModel` class, the `score` function is implemented to calculate the LL of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "print(\"LL: %0.2f (+/- %0.2f)\" % (-scores.mean(), scores.std()))\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important challenge is how to visualize prediction intervals when more than one feature is used. I did not find an elegant answer to this, so you can think about it and let the other people know if you have any ideas. The function below plots predictions and intervals for each feature separately while setting the remaining features to their mean value. The problem is that, when the actual values are used, predictions become noisy as the predictions for nearby points do not coincide because of the dependence on the rest of the features. You can set `use_mean=False` to see the problem. Maybe, moving window average can help? You can try to solve this problem if you are interested..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(model, use_mean=True, keras_model=False):\n",
    "    # calculate mean values\n",
    "    X_means = X.mean(axis=0)\n",
    "    # set up the plot\n",
    "    fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "    index = 0\n",
    "    axs = axs.flatten()\n",
    "    # iterate through the features\n",
    "    for i, col in enumerate(X_columns):\n",
    "        if use_mean:\n",
    "            # set all the features to their means except for the feature to be plotted\n",
    "            X_pred = np.zeros(X.shape)\n",
    "            X_pred[:] = X_means\n",
    "            X_pred[:, i] = X[:, i]\n",
    "        else:\n",
    "            X_pred = X.copy()\n",
    "        # this function will be used to plot keras NN models later\n",
    "        if keras_model:\n",
    "            y_log_s_pred = model.predict(X_pred)\n",
    "            y_pred, log_s_pred = y_log_s_pred[:, 0], y_log_s_pred[:, 1]\n",
    "            # in NN, we predict log(sigma) instead of sigma\n",
    "            s_pred = np.exp(log_s_pred)\n",
    "        else:\n",
    "            y_pred = model.predict_mu(X_pred)\n",
    "            s_pred = model.predict_sigma(X_pred)\n",
    "        X_plot = X_pred[:, i]\n",
    "        # sort values for the correct line plotting\n",
    "        X_plot, y_pred, s_pred = zip(*sorted(zip(X_plot.tolist(), y_pred.tolist(), s_pred.tolist())))\n",
    "        X_plot, y_pred, s_pred = np.array(X_plot), np.array(y_pred), np.array(s_pred)\n",
    "        # plot samples\n",
    "        axs[i].scatter(X[:, i], y, s=20, alpha=0.3)\n",
    "        # plot mean\n",
    "        axs[i].plot(X_plot, y_pred, '-', color='gray', label=\"Model $\\mu\\pm1.96\\sigma$\")\n",
    "        # plot 95% prediction interval\n",
    "        axs[i].plot(X_plot, y_pred - 1.96 * s_pred, '--', color='gray', alpha=0.5)\n",
    "        axs[i].plot(X_plot, y_pred + 1.96 * s_pred, '--', color='gray', alpha=0.5)\n",
    "        axs[i].fill_between(X_plot, y_pred - 1.96 * s_pred, y_pred + 1.96 * s_pred,\n",
    "                         color='gray', alpha=0.2, interpolate=True)\n",
    "        axs[i].legend(loc=\"best\")\n",
    "        axs[i].set_xlabel(col)\n",
    "        axs[i].set_ylabel(y_column)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can fit the model to all the samples for the visualization\n",
    "model.fit(X, y)\n",
    "plot_all(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try a linear model for the standard deviation, $\\sigma(X)=\\alpha_0+\\alpha_1x_1+\\alpha_2x_2+\\dots$. For mean, we will still use the same linear model as before, $\\mu(X)=\\beta_0+\\beta_1x_1+\\alpha_2x_2+\\dots$. We can specify this model using\n",
    "\n",
    ">```model = ModelPoly(1, 1)```\n",
    "\n",
    "Repeat all the steps as for the previous model: calculate CV predictions, calculate their MSE and LL, plot them using `plot_45()`, fit the model to the whole dataset and visualize the predictions using `plot_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelPoly(1, 1)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE for the $\\mu$ has been slightly improved. However, it seems that there is a strange outliner in one of the CV folds for the LL. I could not identify a possible cause myself but you can help me if you want ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try more complex models and/or include other data transformations. Also, since the LL for more complex models becomes non-convex, the optimization results depend on the starting point (and the optimization algorithm itself). So, try also different initial values for the parameters and check if you can further improve the results. You need to find and modify the initialization of the parameters is in the `ModelPoly` class definition above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Optimizing log-likelihood using neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the same task using highly flexible models specified with a neural network which outputs parameters of our distribution. Here, we will use [keras](https://keras.io/) again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras import backend as K # TensorFlow functions\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The code in the cell bellow can be used to plot learning progress. It is completely irrelevant for the class but it might be useful in general. To enable it, you can specify `PlotLosses` as a callback when fitting the model (you will see an example below).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatable plot\n",
    "# a minimal example (sort of)\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class PlotLosses(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #m1, m2 = 'train', 'validation'\n",
    "        m1, m2 = 'loss', 'val_loss'\n",
    "        #m1, m2 = 'acc', 'val_acc'\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get(m1))\n",
    "        self.val_losses.append(logs.get(m2))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig = plt.figure(figsize=(6, 4), dpi=150)\n",
    "        #plt.plot(self.x, np.log(self.losses), label=m1)\n",
    "        #plt.plot(self.x, np.log(self.val_losses), label=m2)\n",
    "        plt.plot(self.x, self.losses, label='train')\n",
    "        plt.plot(self.x, self.val_losses, label='validation', ls='--')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        #ax1.axhline(line, ls=linestyles[i], color=color)\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_learning = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we specify a neural network model. It takes the features $X$ and outputs the two values: $\\mu$ and $\\log\\sigma$. This transformation maps the output values from $[0, +\\inf]$ to $[-\\inf, +\\inf]$ so a linear neuron can be used as an output. Alternatively, you can try exponential or softplus transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_nll_model(input_size): \n",
    "    inputs = Input(shape=(input_size,))    \n",
    "    \n",
    "    # A few examples of different NN architectures:\n",
    "    \n",
    "    # 1. The simplest one (= linear mean and log(sigma))\n",
    "    #output = Dense(2)(inputs)\n",
    "    \n",
    "    # 2. 1 shared hidden layer\n",
    "    #h = Dense(50, activation='tanh')(inputs)\n",
    "    #output = Dense(2)(h)\n",
    "    \n",
    "    # 3. 2 separate hidden layers\n",
    "    hm = Dense(50, activation='tanh')(inputs)\n",
    "    hs = Dense(50, activation='tanh')(inputs)\n",
    "    m = Dense(1)(hm)\n",
    "    s = Dense(1)(hs)\n",
    "    output = Concatenate()([m, s])\n",
    "    \n",
    "    # 4. 1 shared + 2 separate hidden layers\n",
    "    #h = Dense(100, activation='tanh')(inputs)\n",
    "    #hm = Dense(10, activation='tanh')(h)\n",
    "    #hs = Dense(10, activation='tanh')(h)\n",
    "    #m = Dense(1)(hm)\n",
    "    #s = Dense(1)(hs)\n",
    "    #output = Concatenate()([m, s])\n",
    "    \n",
    "    # 5. Your architecture\n",
    "    # ...\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)   \n",
    "    optimiser = RMSprop(lr=0.01, rho=0.9)\n",
    "    # you can try different parameters of the optimiser as well\n",
    "    # ...\n",
    "    model.compile(optimizer=optimiser, loss=keras_nll_loss, metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative LL loss to optimize is specified in the following cell. Here, we use TensorFlow functions implemented in `K` (`from tensorflow.keras import backend as K`), which are similar to the numpy functions but designed to work with TensorFlow variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_nll_loss(y_true, y_pred):\n",
    "    mean_true, log_s_true = y_true[:, 0], None\n",
    "    mean_pred, log_s_pred = y_pred[:, 0], y_pred[:, 1]\n",
    "    # ensure the correct data type\n",
    "    mean_true = K.cast(mean_true, tf.float32)\n",
    "    mean_pred = K.cast(mean_pred, tf.float32)\n",
    "    log_s_pred = K.cast(log_s_pred, tf.float32)\n",
    "    # calculate loss\n",
    "    nll = log_s_pred + K.square(mean_true - mean_pred) / K.exp(2. * log_s_pred) / 2.    \n",
    "    return K.sum(nll, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, `sklearn.model_selection.cross_val_score` does not work for keras models, so we need to implement the CV procedure ourselves. Note that the number of epochs and batch size are hyper-parameters as well (yes, NNs have a lot of them...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_keras(model, X, y, cv, batch_size=32, epochs=100):\n",
    "    y_pred = []\n",
    "    for fold_i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        print(\"Calculating CV fold =\", fold_i)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #\n",
    "        model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  #callbacks=[plot_learning] # uncomment this line if you want to plot learning progress\n",
    "                 )\n",
    "        y_s_pred = model.predict(X_test)\n",
    "        y_pred += y_s_pred[:, 0].tolist()\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_keras(model, X, y, cv, scoring, batch_size=32, epochs=100):\n",
    "    scores = []\n",
    "    for fold_i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        print(\"Calculating CV fold =\", fold_i)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #\n",
    "        model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  #callbacks=[plot_learning] # uncomment this line if you want to plot learning progress\n",
    "                 )\n",
    "        y_s_pred = model.predict(X_test)\n",
    "        y_pred = y_s_pred[:, 0]\n",
    "        s_pred = np.exp(y_s_pred[:, 1])\n",
    "        if scoring == mean_squared_error:\n",
    "            scores.append(scoring(y_test, y_pred))\n",
    "        else:\n",
    "            scores.append(scoring(y_test, y_s_pred))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to implement the LL scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LL_keras(y, y_s_pred):\n",
    "    return K.eval(keras_nll_loss(y.reshape(-1, 1), y_s_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, everything is ready to try a keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_nll_model(X.shape[1])\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "y_pred = cross_val_predict_keras(model, X, y, cv=kf, epochs=epochs, batch_size=batch_size)\n",
    "error = mean_squared_error(y, y_pred)\n",
    "print(\"MSE: {:0.2f}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_45(y, y_pred)\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          #callbacks=[plot_learning]\n",
    "         )\n",
    "plot_all(model, keras_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score_keras(model, X, y, cv=kf, scoring=LL_keras, epochs=epochs, batch_size=batch_size)\n",
    "print(\"LL: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the model without hidden layers should be similar to the `PolyModel(1, 1)`. The results of the model with 2 separate hidden layers show much better MSE but lower LL. Try different NN architectures (number of hidden layers, number of neurons in the hidden layers, activation function) as well as the optimization parameters (e.g., learning rate) to see if it can improve modeling results. Repeat all the steps as before: calculate CV predictions, calculate their MSE and LL, plot them using `plot_45()`, fit the model to the whole dataset and visualize the predictions using `plot_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... You can modify keras_nll_model() and re-run the code above ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Quantile regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us finally do quantile regression which is another way to approximate a distribution. Instead of learning the PDF, it learns the quantile function, which the inverse of the CDF. It requires specification of a quantile model $Q_\\tau(X)$ in some parametric (or non-parametric) form and optimization of the corresponding tilted loss. \n",
    "\n",
    "*We will not do any CV below for the sake of brevity, but remember that it is still necessary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Quantile regression using multiple linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first exercise, we will optimize the tilted loss without classes and sklearn. First, we need to define our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant model, which outputs one value independently of X\n",
    "def model_const_func(X, params):\n",
    "    return np.full(X.shape[0], params[0])\n",
    "\n",
    "# simple linear model without feature transformations\n",
    "def model_lin_func(X, params):\n",
    "    return np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tilted (a.k.a. \"quantile\") loss has the following form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(X, y, q, model_y_func, params_y):\n",
    "    # calculate model's predictions\n",
    "    y_pred = model_y_func(X, params_y)\n",
    "    # calculate loss\n",
    "    loss = np.sum(np.maximum(q*(y-y_pred), (q-1)*(y-y_pred)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`functools.partial` allows to set a subset of the function parameters, so they do not need to be defined when it is called later (similar to setting default values for the parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will use the `scipy` optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "# you can try the constant model if you want\n",
    "#y_func_model = model_const_func\n",
    "y_func_model = model_lin_func\n",
    "#\n",
    "quant_models = []\n",
    "for q in quantiles:\n",
    "    # minimize function should have only one parameter, that's why we need functools.partial\n",
    "    loss = partial(quantile_loss, X, y, q, y_func_model)\n",
    "    # set initial values for the parameters (a starting point)\n",
    "    #params_y = np.full(1, 0.1) # for the constant model\n",
    "    params_y = np.full(X.shape[1] + 1, 0.1) # for the linear model\n",
    "    # optimize\n",
    "    res = minimize(loss, params_y, method='Powell', options={\n",
    "        'xtol': 1e-8, \n",
    "        'disp': True\n",
    "    })\n",
    "    quant_models.append(partial(y_func_model, params=res.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting, we will use the function below. Here, we have the same challenges with multidimensional data visualization as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantiles(model, quantiles, use_median=True, keras_model=False):\n",
    "    # calculate median values\n",
    "    X_means = np.median(X, axis=0)\n",
    "    fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "    axs = axs.flatten()\n",
    "    # iterate through the features\n",
    "    for i, col in enumerate(X_columns):\n",
    "        if use_median:\n",
    "            # set all the features to their medians except for the feature to be plotted\n",
    "            X_pred = np.zeros(X.shape)\n",
    "            X_pred[:] = X_means\n",
    "            X_pred[:, i] = X[:, i]\n",
    "        else:\n",
    "            X_pred = X.copy()\n",
    "        axs[i].scatter(X[:, i], y, s=20, alpha=0.3)\n",
    "        # this function will be used to plot keras NN models later\n",
    "        if keras_model:\n",
    "            q_pred = model.predict(X_pred)\n",
    "            y_pred_all = q_pred.T\n",
    "        else:\n",
    "            y_pred_all = [q_func(X_pred) for q_func in model]\n",
    "        for q, y_pred in zip(quantiles, y_pred_all):\n",
    "            X_plot = X[:, i]\n",
    "            X_plot, y_pred = zip(*sorted(zip(X_plot.tolist(), y_pred.tolist())))\n",
    "            X_plot, y_pred = np.array(X_plot), np.array(y_pred)\n",
    "            axs[i].plot(X_plot, y_pred, '-', label=str(q))\n",
    "        axs[i].legend(loc=\"best\")\n",
    "        axs[i].set_xlabel(col)\n",
    "        axs[i].set_ylabel(y_column)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantiles(quant_models, quantiles, use_median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the crossings of the estimated quantile functions — they should be completely absent in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Multi-output quantile regression using neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can use a NN for this task. We will calculate the following quantiles using a multi-output NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tilted loss in keras can be defined as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss_nn(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for q_i, q in enumerate(quantiles):\n",
    "        e = y_true - y_pred[:, q_i:q_i+1]\n",
    "        loss += K.mean(K.maximum(q*e, (q-1)*e))\n",
    "    return loss# / len(quantiles) # normalization here does not affect the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try a linear NN model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_linear_model(input_size, output_size, loss): \n",
    "    inputs = Input(shape=(input_size,))\n",
    "    output = Dense(output_size)(inputs)\n",
    "    model = Model(inputs=inputs, outputs=output)   \n",
    "    optimiser = RMSprop(lr=0.01, rho=0.9)\n",
    "    # you can try different parameters of the optimiser\n",
    "    # ...\n",
    "    model.compile(optimizer=optimiser, loss=loss, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_linear_model(X.shape[1], len(quantiles), quantile_loss_nn)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          #callbacks=[plot_learning] # uncomment this line if you want to plot learning progress\n",
    "         )\n",
    "plot_quantiles(model, quantiles, use_median=True, keras_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we get much less (or even zero) crossings, which is a very good sign! Let us try a nonlinear model as well (do the same plot using `plot_quantiles()` as for the linear model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_nonlinear_model(input_size, output_size, loss): \n",
    "    inputs = Input(shape=(input_size,))\n",
    "    h = Dense(100, activation='relu')(inputs)\n",
    "    #h = Dense(50, activation='relu')(h)\n",
    "    # try different architectures\n",
    "    # ...\n",
    "    output = Dense(output_size)(h)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    optimiser = RMSprop(lr=0.01, rho=0.9)\n",
    "    # you can try different parameters of the optimiser\n",
    "    # ...\n",
    "    model.compile(optimizer=optimiser, loss=loss, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_nonlinear_model(X.shape[1], len(quantiles), quantile_loss_nn)\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          #callbacks=[plot_learning]\n",
    "         )\n",
    "plot_quantiles(model, quantiles, use_median=True, keras_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the complete absence of the crossings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also use the median instead of the mean for the price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.5, 0.5] # the second output will not be used\n",
    "model = keras_nonlinear_model(X.shape[1], len(quantiles), quantile_loss_nn)\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "y_pred = cross_val_predict_keras(model, X, y, cv=kf, batch_size=batch_size, epochs=epochs)\n",
    "error = mean_squared_error(y, y_pred)\n",
    "print(\"MSE: {:0.2f}\".format(error))\n",
    "plot_45(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Alternative implementation of log-likelihood optimisation using linear regression without classes and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def model_const_func(X, params):\n",
    "    return np.full(X.shape[0], params[0])\n",
    "\n",
    "def model_lin_func(X, params):\n",
    "    return np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), params)\n",
    "\n",
    "def NLL(X, y, model_y_func, model_s_func, params_y_n, params_y_s):\n",
    "    nll = np.log(model_s_func(X, params_y_s[params_y_n:])**2)\n",
    "    nll += (y - model_y_func(X, params_y_s[:params_y_n]))**2 / model_s_func(X, params_y_s[params_y_n:])**2\n",
    "    nll = np.sum(nll) / 2.0 # sum over samples\n",
    "    return nll\n",
    "\n",
    "\n",
    "# define models\n",
    "y_func_model = model_lin_func\n",
    "params_y = np.full(X.shape[1] + 1, 0.1) # linear model\n",
    "#s_func_model = model_const_func\n",
    "#params_s = np.full((1,), 10.0) # const model\n",
    "s_func_model = model_lin_func\n",
    "params_s = np.full(X.shape[1] + 1, 0.1)\n",
    "params_y_s = np.concatenate([params_y, params_s])\n",
    "params_y_n = len(params_y)\n",
    "# define loss and optimise\n",
    "loss = partial(NLL, X, y, y_func_model, s_func_model, params_y_n)\n",
    "res = minimize(loss, params_y_s, method='Powell', options={\n",
    "    'xtol': 1e-8, \n",
    "    'disp': True\n",
    "})\n",
    "# predict\n",
    "y_pred = y_func_model(X, res.x[:len(params_y)])\n",
    "s_pred = s_func_model(X, res.x[len(params_y):])\n",
    "plot_45(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #\n",
    "    y_func_model = model_lin_func\n",
    "    params_y = np.full(X.shape[1] + 1, 0.1)\n",
    "    #\n",
    "    s_func_model = model_const_func\n",
    "    params_s = np.full((1,), 0.1)\n",
    "    #s_func_model = model_lin_func\n",
    "    #params_s = np.full(X.shape[1] + 1, 0.1)\n",
    "    #\n",
    "    params_y_s = np.concatenate([params_y, params_s])\n",
    "    params_y_n = len(params_y)\n",
    "    loss = partial(NLL, X_train, y_train, y_func_model, s_func_model, params_y_n)\n",
    "    res = minimize(loss, params_y_s, method='Powell', options={\n",
    "        'xtol': 1e-8, \n",
    "        'disp': True, \n",
    "        'maxiter': 1000\n",
    "    })\n",
    "    y_pred = y_func_model(X_test, res.x[:len(params_y)])\n",
    "    s_pred = s_func_model(X_test, res.x[len(params_y):])\n",
    "    scores.append(mean_squared_error(y_test, y_pred))\n",
    "scores = np.array(scores)\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
